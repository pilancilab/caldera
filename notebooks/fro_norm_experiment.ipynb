{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caldera.decomposition.layer_quantization import *\n",
    "from caldera.decomposition.weight_compression import *\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = \"meta-llama/Llama-2-7b-hf\"\n",
    "HESSIAN_SAVE_PATH = \"../data/Hessians-Llama-2-7b-6144\"\n",
    "DEVICE = \"cuda:0\"\n",
    "RANK = 256\n",
    "QLR_ITERS = 5\n",
    "LPLR_ITERS = 10\n",
    "\n",
    "LAYER = 25\n",
    "SUBLAYER = TransformerSubLayers.GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_BITS = 4\n",
    "DOWNDATE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, instantiate a weight compressor\n",
    "weight_comp = ActivationAwareWeightCompressor(\n",
    "    model_params=ModelParameters(\n",
    "        base_model=BASE_MODEL\n",
    "    ),\n",
    "    data_params=DataParameters(),\n",
    "    hessian_save_path=HESSIAN_SAVE_PATH,\n",
    "    quant_params=CalderaParams(\n",
    "        Q_bits=2,\n",
    "        L_bits=LR_BITS, R_bits=LR_BITS,\n",
    "        lattice_quant_LR=True,\n",
    "        rank=RANK,\n",
    "        activation_aware_Q=True,\n",
    "        activation_aware_LR=True,\n",
    "        hadamard_transform=True,\n",
    "        iters=QLR_ITERS,\n",
    "        lplr_iters=LPLR_ITERS,\n",
    "        rand_svd=True,\n",
    "        Q_hessian_downdate=DOWNDATE,\n",
    "        update_order=[\"LR\", \"Q\"]\n",
    "    ),\n",
    "    compute_hessians=False,\n",
    "    quant_device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, get the layer quantizer for the particular layer you want to quantize\n",
    "layer_quant = weight_comp.get_layer_quantizer(LAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant.compress_sublayer(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the errors\n",
    "layer_quant.plot_errors(SUBLAYER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"LR\" refers to the Frobeius norm error after the LPLR step, and \"Q\" refers to the Frobenius norm error after the LDLQ step. The first-iteration error for LR will be high, since Q is still set to zero. So, there's the option for you to omit the first iteration while plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant.plot_errors(SUBLAYER, plot_first_iter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how to get the error arrays if you want to plot errors for different quatization parameters on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = layer_quant.sublayer_info[SUBLAYER].caldera.errors\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also export the errors as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTFILE = \"errors.json\" # change this!\n",
    "layer_quant.export_errors_json(SUBLAYER, OUTFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
