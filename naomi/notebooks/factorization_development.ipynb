{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a very messy notebook for current development/scratch work.\n",
    "\n",
    "#### `test_decomposition_schemes.ipynb` has more formalized progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsagan/micromamba/envs/lplr/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from phantominator import shepp_logan\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "import torch_dct as dct\n",
    "import pywt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (weight_compressors.py, line 1071)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/micromamba/envs/lplr/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3553\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[2], line 1\u001b[0m\n    from lplr_llm.experimental import make_sparse\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/peft/winter24-lplr-extension/src/lplr_llm/experimental.py:5\u001b[0;36m\n\u001b[0;31m    from lplr_llm.weight_compressors import alternating_mixed_lplr\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/peft/winter24-lplr-extension/src/lplr_llm/weight_compressors.py:1071\u001b[0;36m\u001b[0m\n\u001b[0;31m    def _get_Q(self, Q_left, Q_right)\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "from lplr_llm.experimental import make_sparse\n",
    "from lplr_llm.quantization import QuantizerFactory, simulated_quant\n",
    "from lplr_llm.error_metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DEVICE = \"cuda:2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:58<00:00, 29.14s/it]\n"
     ]
    }
   ],
   "source": [
    "llama = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\", token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model.layers.11.self_attn.q_proj.weight', 4096, 4096)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_name, X_lla = list(llama.named_parameters())[100]\n",
    "X_lla = X_lla.detach().to(DEFAULT_DEVICE)\n",
    "n, d = X_lla.shape\n",
    "layer_name, n, d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUR Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cur_decomposition(X, c, r, k=None):\n",
    "    if k is None:\n",
    "        k = min(*X.shape)\n",
    "\n",
    "    U, _, VT = torch.linalg.svd(X, full_matrices=False)\n",
    "\n",
    "    p_col = 1/k * torch.norm(VT.T[:, :k], dim=1) ** 2\n",
    "    p_row =  1/k * torch.norm(U[:, :k], dim=1) ** 2\n",
    "\n",
    "    keep_rows = torch.rand(X.shape[0]).to(X.device) < r*p_row\n",
    "    while torch.sum(keep_rows) < r:\n",
    "        diff = r - torch.sum(keep_rows)\n",
    "        keep_rows = keep_rows | (torch.rand(X.shape[0]).to(X.device) < diff*p_row)\n",
    "    while torch.sum(keep_rows) > r:\n",
    "        keep_rows[torch.randint(X.shape[0], size=(1,))] = False\n",
    "\n",
    "    keep_cols = torch.rand(X.shape[1]).to(X.device) < c*p_col\n",
    "    while torch.sum(keep_cols) < c:\n",
    "        diff = c - torch.sum(keep_cols)\n",
    "        keep_cols = keep_cols | (torch.rand(X.shape[1]).to(X.device) < diff*p_col)\n",
    "    while torch.sum(keep_cols) > c:\n",
    "        keep_cols[torch.randint(X.shape[1], size=(1,))] = False\n",
    "\n",
    "    C = X[:, keep_cols]\n",
    "    R = X[keep_rows, :]\n",
    "\n",
    "    U = torch.linalg.pinv(C) @ X @ torch.linalg.pinv(R)\n",
    "\n",
    "    return C, U, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = np.log(k / 0.04) # log(k/epsilon^2) oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472.17657012658384"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k*oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "C, U, R = cur_decomposition(X_lla, int(k*oversample), int(k*oversample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hat_CUR = C @ U @ R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8829, device='cuda:2')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(X_lla - X_hat_CUR) / torch.norm(X_lla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, Sigma, VT = torch.linalg.svd(X_lla, full_matrices=False)\n",
    "X_hat_SVD = U[:, :k] @ torch.diag(Sigma[:k]) @ VT[:k, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8770, device='cuda:2')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(X_lla - X_hat_SVD) / torch.norm(X_lla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The necessary oversampling to get the same accuracy seems prohibitive, but https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9335842&tag=1 gets good results using CUR so maybe the decrease in Frobenius norm accuracy at the same bitrate doesn't degrade finetuning performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pruning_matrix_approximation(X, block_size=4, n_segments=4):\n",
    "#     X_orig = X\n",
    "#     segment_length = X.shape[1] // n_segments\n",
    "\n",
    "#     for segment_start in range(0, X.shape[1], segment_length):\n",
    "\n",
    "#         errors = []\n",
    "#         for col in tqdm(range(\n",
    "#             segment_start, \n",
    "#             min(segment_start+segment_length, X.shape[1]),\n",
    "#             block_size\n",
    "#         )):\n",
    "#             X_minus_col = torch.hstack((X[:, :col], X[:, col+block_size:]))\n",
    "#             w = torch.linalg.lstsq(X_minus_col, X[:, col:col+block_size])[0]\n",
    "#             err = torch.norm(X[:, col:col+block_size] - X_minus_col @ w) / \\\n",
    "#                 torch.norm(X[:, col:col+block_size])\n",
    "#             errors.append(err.item())\n",
    "#         col = np.argmin(errors)\n",
    "#         X_minus_col = torch.hstack((X[:, :col], X[:, col+block_size:]))\n",
    "#         w = torch.linalg.lstsq(X_minus_col, X[:, col:col+block_size])[0]\n",
    "#         X = torch.hstack((X[:, :col], X_minus_col @ w, X[:, col+block_size:]))\n",
    "#     return X, (torch.norm(X - X_orig) / torch.norm(X)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_lla\n",
    "col = 50\n",
    "step = 4\n",
    "d = X.shape[1]\n",
    "X1 = torch.hstack((X[:, :col], X[:, col+step:]))\n",
    "W1 = torch.linalg.lstsq(X1, X[:, col:col+step])[0]\n",
    "P1 = torch.zeros(d, d).to(X.device)\n",
    "P1[torch.arange(col), torch.arange(col)] = 1\n",
    "P1[torch.arange(col, d-step), torch.arange(col+step, d)] = 1\n",
    "P1[torch.arange(d-step, d), torch.arange(col, col+step)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hat = X1 @ torch.hstack((torch.eye(X1.shape[1]).to(X.device), W1)) @ P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0004, device='cuda:2')"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(X - X_hat) / torch.norm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step = 32\n",
    "# segment_len = 32 * step\n",
    "# segments = X.shape[1] // segment_len\n",
    "# iters = segments * 23\n",
    "\n",
    "# cols_to_keep = torch.arange(4096) >= 0\n",
    "# for i, _ in enumerate(tqdm(range(iters))):\n",
    "#     errors = []\n",
    "\n",
    "#     if not torch.all(cols_to_keep[col:col+step]):\n",
    "#         errors.append(float('inf'))\n",
    "#         continue\n",
    "#     cols_to_keep_copy = cols_to_keep.clone()\n",
    "\n",
    "#     cols_to_keep_copy[col:col+step] = False\n",
    "#     X_minus_cols = X[:, cols_to_keep_copy]\n",
    "#     cols = X[:, ~cols_to_keep_copy]\n",
    "#     W = torch.linalg.lstsq(X_minus_cols, cols)[0]\n",
    "#     err = torch.norm(cols - X_minus_cols @ W) / torch.norm(cols)\n",
    "#     errors.append(err.item())\n",
    "    \n",
    "#     col = np.argmin(errors)*step + (i%segments)*segment_len\n",
    "#     # print(col, np.min(errors), sum(cols_to_keep).item())\n",
    "#     cols_to_keep[col:col+step] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model.layers.11.self_attn.q_proj.weight', 4096, 4096)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_name, X_lla = list(llama.named_parameters())[100]\n",
    "X_lla = X_lla.detach().to(DEFAULT_DEVICE)\n",
    "n, d = X_lla.shape\n",
    "layer_name, n, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n < d:\n",
    "    X_lla = X_lla.T\n",
    "    n, d = d, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, Sigma, VT = torch.linalg.svd(X_lla)\n",
    "Xk = U[:, :64] @ torch.diag(Sigma[:64]) @ VT[:64, :]\n",
    "X = X_lla - Xk\n",
    "# X = X_lla.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = (2944 + 63) // 64 * 64 ## Must be a multiple of 64 or block quantization doesn't work\n",
    "\n",
    "## For MLP wide matrix\n",
    "# m = (d - n + 2400 + 63) // 64 * 64\n",
    "## For MLP tall matrix\n",
    "# m = (2400 + 63) // 64 * 64\n",
    "\n",
    "cols_to_keep = torch.arange(X.shape[1]) >= 0\n",
    "_, _, VT = torch.linalg.svd(X)\n",
    "col_idxs = torch.topk(torch.norm(VT.T[:, -m:], dim=1).cpu(), m).indices\n",
    "\n",
    "cols_to_keep[col_idxs] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_minus_cols = X[:, cols_to_keep]\n",
    "cols = X[:, ~cols_to_keep]\n",
    "W = torch.linalg.lstsq(X_minus_cols, cols)[0]\n",
    "err = torch.norm(cols - X_minus_cols @ W) / torch.norm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_8b = QuantizerFactory(\"normal\").get_quantizer(8)\n",
    "quant_4b = QuantizerFactory(\"normal\").get_quantizer(4)\n",
    "quant_2b = QuantizerFactory(\"uniform_clipped\").get_quantizer(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 14.07it/s]\n"
     ]
    }
   ],
   "source": [
    "quant = quant_4b\n",
    "bits = 4\n",
    "err_norm = FroError(X_lla)\n",
    "\n",
    "# X_left = X_minus_cols\n",
    "# X_right = W\n",
    "\n",
    "X_left = simulated_quant(quant, X_minus_cols)\n",
    "X_right = simulated_quant(quant, torch.linalg.lstsq(X_left, cols)[0])\n",
    "\n",
    "A = torch.hstack((torch.eye(X_right.shape[0]).to(X_right.device), X_right))\n",
    "B = torch.hstack((X_minus_cols, cols))\n",
    "best_err = err_norm.error(X_hat=X_left @ A, X_exact=B)\n",
    "best_factors = X_left, X_right\n",
    "for _ in tqdm(range(15)):\n",
    "    A = torch.hstack((torch.eye(X_right.shape[0]).to(X_right.device), X_right))\n",
    "    B = torch.hstack((X_minus_cols, cols))\n",
    "    X_left = simulated_quant(quant, torch.linalg.lstsq(A.T, B.T)[0].T)\n",
    "    X_right = simulated_quant(quant, torch.linalg.lstsq(X_left, cols)[0])\n",
    "\n",
    "    A = torch.hstack((torch.eye(X_right.shape[0]).to(X_right.device), X_right))\n",
    "    B = torch.hstack((X_minus_cols, cols))\n",
    "    err = err_norm.error(X_hat=X_left @ A, X_exact=B)\n",
    "    # print(err)\n",
    "    if err < best_err:\n",
    "        best_err = err\n",
    "        best_factors = X_left, X_right\n",
    "X_left, X_right = best_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2B Quant: 3.355443e+07 bits\n",
      "4B Quant: 6.710886e+07 bits\n",
      "Ours: 3.244442e+07 bits\n"
     ]
    }
   ],
   "source": [
    "print(\"2B Quant: %e bits\" % (X.shape[1] * X.shape[0] * 2))\n",
    "print(\"4B Quant: %e bits\" % (X.shape[1] * X.shape[0] * 4))\n",
    "print(\"Ours: %e bits\" % (X_minus_cols.shape[0]*X_minus_cols.shape[1]*bits + W.shape[0]*W.shape[1]*bits  + X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2B Quant error: 0.22785277664661407\n",
      "4B Quant error: 0.030100679025053978\n",
      "Our error: 0.12371369451284409\n"
     ]
    }
   ],
   "source": [
    "# X_left A \\approx B\n",
    "err_norm = SpectralError(X_lla)\n",
    "\n",
    "A = torch.hstack((torch.eye(X_right.shape[0]).to(X_right.device), X_right))\n",
    "B = torch.hstack((X_minus_cols, cols))\n",
    "err = err_norm.error(X_hat=X_left @ A, X_exact=B)\n",
    "err_2b = err_norm.error(X_hat=simulated_quant(quant_2b, X), X_exact=X)\n",
    "err_4b = err_norm.error(X_hat=simulated_quant(quant_4b, X), X_exact=X)\n",
    "\n",
    "print(f\"2B Quant error: {(err_2b)}\")\n",
    "print(f\"4B Quant error: {(err_4b)}\")\n",
    "print(f\"Our error: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Sparse + Quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrinkage(tau, x):\n",
    "    return torch.sign(x) * torch.maximum(torch.abs(x) - tau, torch.zeros_like(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_plus_quantized(\n",
    "    X,\n",
    "    lmbda,\n",
    "    B=4,\n",
    "    BS=8,\n",
    "    iters=10\n",
    "):\n",
    "    quant = QuantizerFactory(\"normal\").get_quantizer(B)\n",
    "    quant_S = QuantizerFactory(\"normal\").get_quantizer(BS)\n",
    "\n",
    "    Q = simulated_quant(quant, X)\n",
    "    S = torch.zeros_like(X)\n",
    "    for _ in range(iters):\n",
    "        Q = simulated_quant(quant, X - S)\n",
    "        S = shrinkage(lmbda, X - Q)\n",
    "        if BS < 16:\n",
    "            S = simulated_quant(quant_S, S)\n",
    "\n",
    "        # enforce actual sparsity\n",
    "        S = S * (torch.abs(S) > torch.abs(X).max() * 1e-2)\n",
    "        print(f\"Fro error: {(torch.norm(X - Q - S) / torch.norm(X)).item()}\")\n",
    "        print(f\"\\tNonzero: {torch.sum(S != 0).item() / (4096*4096) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fro error: 0.08386176079511642\n",
      "\tNonzero percent: 1.1759698390960693\n",
      "Fro error: 0.08386176079511642\n",
      "\tNonzero percent: 1.1759698390960693\n",
      "Fro error: 0.08386176079511642\n",
      "\tNonzero percent: 1.1759698390960693\n",
      "Fro error: 0.08386176079511642\n",
      "\tNonzero percent: 1.1759698390960693\n",
      "Fro error: 0.08386176079511642\n",
      "\tNonzero percent: 1.1759698390960693\n",
      "Fro error: 0.08386176079511642\n",
      "\tNonzero percent: 1.1759698390960693\n",
      "Fro error: 0.08386176079511642\n",
      "\tNonzero percent: 1.1759698390960693\n",
      "Fro error: 0.08386176079511642\n",
      "\tNonzero percent: 1.1759698390960693\n",
      "Fro error: 0.08386176079511642\n",
      "\tNonzero percent: 1.1759698390960693\n",
      "Fro error: 0.08386176079511642\n",
      "\tNonzero percent: 1.1759698390960693\n"
     ]
    }
   ],
   "source": [
    "sparse_plus_quantized(X_lla, 1e-3, B=4, BS=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151666032"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0.22*4096*4096*32 + 4096*4096*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67108864"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4096*4096*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
