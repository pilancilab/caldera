{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glog\n",
    "glog.setLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lplr_llm.activation_aware.weight_compression import *\n",
    "from lplr_llm.activation_aware.layer_quantization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = \"meta-llama/Llama-2-7b-hf\"\n",
    "HESSIAN_SAVE_PATH = \"../../data/hessians/llama-2-7b\"\n",
    "DEVICE = \"cuda:7\"\n",
    "RANK = 128\n",
    "QLR_ITERS = 5\n",
    "LPLR_ITERS = 10\n",
    "\n",
    "LAYER = 23\n",
    "SUBLAYER = TransformerSubLayers.VALUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular 4B Factors (no Gaussian Transform)\n",
    "\n",
    "For speed of testing, we are using lattice quantization instead of LDLQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_comp_default_4B_factors = ActivationAwareWeightCompressor(\n",
    "    model_params=ModelParameters(\n",
    "        base_model=BASE_MODEL\n",
    "    ),\n",
    "    data_params=DataParameters(),\n",
    "    hessian_save_path=HESSIAN_SAVE_PATH,\n",
    "    quant_params=ActivationAwareQuantParams(\n",
    "        Q_bits=2,\n",
    "        L_bits=4, R_bits=4,\n",
    "        rank=RANK,\n",
    "        activation_aware_Q=False,\n",
    "        activation_aware_LR=True,\n",
    "        hadamard_transform=False,\n",
    "        compute_quantized_component=True,\n",
    "        iters=QLR_ITERS,\n",
    "        lplr_iters=1,\n",
    "        rand_svd=True,\n",
    "        update_order=[\"Q\", \"LR\"],\n",
    "        verbose=True\n",
    "    ),\n",
    "    compute_hessians=False,\n",
    "    quant_device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant = weight_comp_default_4B_factors.get_layer_quantizer(LAYER)\n",
    "layer_quant.compress_sublayer(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([round(val, 4) for val in layer_quant.sublayer_info[SUBLAYER].errors['LR']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant.min_error(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant.plot_errors(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longer, not verbose\n",
    "weight_comp_default_4B_factors = ActivationAwareWeightCompressor(\n",
    "    model_params=ModelParameters(\n",
    "        base_model=BASE_MODEL\n",
    "    ),\n",
    "    data_params=DataParameters(),\n",
    "    hessian_save_path=HESSIAN_SAVE_PATH,\n",
    "    quant_params=ActivationAwareQuantParams(\n",
    "        Q_bits=2,\n",
    "        L_bits=4, R_bits=4,\n",
    "        lattice_quant_LR=True,\n",
    "        rank=RANK,\n",
    "        activation_aware_Q=False,\n",
    "        activation_aware_LR=True,\n",
    "        hadamard_transform=False,\n",
    "        compute_quantized_component=True,\n",
    "        iters=30,\n",
    "        lplr_iters=1,\n",
    "        rand_svd=True,\n",
    "        update_order=[\"Q\", \"LR\"],\n",
    "    ),\n",
    "    compute_hessians=False,\n",
    "    quant_device=DEVICE,\n",
    ")\n",
    "layer_quant_longer = weight_comp_default_4B_factors.get_layer_quantizer(LAYER)\n",
    "layer_quant_longer.compress_sublayer(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant_longer.min_error(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant_longer.plot_errors(SUBLAYER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4B Factors with Hadamard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_comp_4B_factors_incoh = ActivationAwareWeightCompressor(\n",
    "    model_params=ModelParameters(\n",
    "        base_model=BASE_MODEL\n",
    "    ),\n",
    "    data_params=DataParameters(),\n",
    "    hessian_save_path=HESSIAN_SAVE_PATH,\n",
    "    quant_params=ActivationAwareQuantParams(\n",
    "        Q_bits=2,\n",
    "        L_bits=4, R_bits=4,\n",
    "        lattice_quant_LR=True,\n",
    "        rank=RANK,\n",
    "        activation_aware_Q=False,\n",
    "        activation_aware_LR=True,\n",
    "        hadamard_transform=False,\n",
    "        hadamard_transform_L=True,\n",
    "        hadamard_transform_R=True,\n",
    "        iters=5,\n",
    "        lplr_iters=1,\n",
    "        rand_svd=True,\n",
    "        update_order=[\"Q\", \"LR\"],\n",
    "        verbose=True\n",
    "    ),\n",
    "    compute_hessians=False,\n",
    "    quant_device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant2 = weight_comp_4B_factors_incoh.get_layer_quantizer(LAYER)\n",
    "layer_quant2.compress_sublayer(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([round(val, 4) for val in layer_quant2.sublayer_info[SUBLAYER].errors['LR']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant2.min_error(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant2.plot_errors(SUBLAYER, plot_first_iter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# longer, not verbose\n",
    "weight_comp_4B_factors_incoh = ActivationAwareWeightCompressor(\n",
    "    model_params=ModelParameters(\n",
    "        base_model=BASE_MODEL\n",
    "    ),\n",
    "    data_params=DataParameters(),\n",
    "    hessian_save_path=HESSIAN_SAVE_PATH,\n",
    "    quant_params=ActivationAwareQuantParams(\n",
    "        Q_bits=2,\n",
    "        L_bits=4, R_bits=4,\n",
    "        lattice_quant_LR=True,\n",
    "        rank=RANK,\n",
    "        activation_aware_Q=False,\n",
    "        activation_aware_LR=True,\n",
    "        hadamard_transform=False,\n",
    "        hadamard_transform_L=True,\n",
    "        hadamard_transform_R=True,\n",
    "        iters=30,\n",
    "        lplr_iters=1,\n",
    "        rand_svd=True,\n",
    "        update_order=[\"Q\", \"LR\"]\n",
    "    ),\n",
    "    compute_hessians=False,\n",
    "    quant_device=DEVICE,\n",
    ")\n",
    "layer_quant_longer2 = weight_comp_4B_factors_incoh.get_layer_quantizer(LAYER)\n",
    "layer_quant_longer2.compress_sublayer(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant_longer2.min_error(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant_longer2.plot_errors(SUBLAYER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4B Factors with Haar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_comp_4B_factors_incoh_2 = ActivationAwareWeightCompressor(\n",
    "    model_params=ModelParameters(\n",
    "        base_model=BASE_MODEL\n",
    "    ),\n",
    "    data_params=DataParameters(),\n",
    "    hessian_save_path=HESSIAN_SAVE_PATH,\n",
    "    quant_params=ActivationAwareQuantParams(\n",
    "        Q_bits=2,\n",
    "        L_bits=4, R_bits=4,\n",
    "        lattice_quant_LR=True,\n",
    "        rank=RANK,\n",
    "        activation_aware_Q=False,\n",
    "        activation_aware_LR=True,\n",
    "        hadamard_transform=True,\n",
    "        hadamard_transform_L=True,\n",
    "        Haar_transform_L=False,\n",
    "        iters=QLR_ITERS,\n",
    "        lplr_iters=LPLR_ITERS,\n",
    "        rand_svd=True,\n",
    "        update_order=[\"Q\", \"LR\"],\n",
    "        verbose=True\n",
    "    ),\n",
    "    compute_hessians=False,\n",
    "    quant_device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant3 = weight_comp_4B_factors_incoh_2.get_layer_quantizer(LAYER)\n",
    "layer_quant3.compress_sublayer(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant3.min_error(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([round(val, 4) for val in layer_quant3.sublayer_info[SUBLAYER].errors['LR']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant3.plot_errors(SUBLAYER, plot_first_iter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_comp_4B_factors_incoh_2 = ActivationAwareWeightCompressor(\n",
    "    model_params=ModelParameters(\n",
    "        base_model=BASE_MODEL\n",
    "    ),\n",
    "    data_params=DataParameters(),\n",
    "    hessian_save_path=HESSIAN_SAVE_PATH,\n",
    "    quant_params=ActivationAwareQuantParams(\n",
    "        Q_bits=2,\n",
    "        L_bits=4, R_bits=4,\n",
    "        lattice_quant_LR=True,\n",
    "        rank=RANK,\n",
    "        activation_aware_Q=False,\n",
    "        activation_aware_LR=True,\n",
    "        hadamard_transform=True,\n",
    "        incoherence_process_LR=True,\n",
    "        Haar_transform_L=True,\n",
    "        iters=50,\n",
    "        lplr_iters=LPLR_ITERS,\n",
    "        rand_svd=True,\n",
    "        update_order=[\"Q\", \"LR\"],\n",
    "        verbose=False\n",
    "    ),\n",
    "    compute_hessians=False,\n",
    "    quant_device=DEVICE,\n",
    ")\n",
    "layer_quant_longer3 = weight_comp_4B_factors_incoh_2.get_layer_quantizer(LAYER)\n",
    "layer_quant_longer3.compress_sublayer(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant_longer3.min_error(SUBLAYER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For comparison: 16B Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_comp_16B_factors = ActivationAwareWeightCompressor(\n",
    "    model_params=ModelParameters(\n",
    "        base_model=BASE_MODEL\n",
    "    ),\n",
    "    data_params=DataParameters(),\n",
    "    hessian_save_path=HESSIAN_SAVE_PATH,\n",
    "    quant_params=ActivationAwareQuantParams(\n",
    "        Q_bits=2,\n",
    "        L_bits=16, R_bits=16,\n",
    "        lattice_quant_LR=False,\n",
    "        rank=RANK,\n",
    "        activation_aware_Q=False,\n",
    "        activation_aware_LR=True,\n",
    "        incoherence_process_LR=False,\n",
    "        iters=50,\n",
    "        lplr_iters=1,\n",
    "        rand_svd=True,\n",
    "        update_order=[\"Q\", \"LR\"]\n",
    "    ),\n",
    "    compute_hessians=False,\n",
    "    quant_device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant4 = weight_comp_16B_factors.get_layer_quantizer(LAYER)\n",
    "layer_quant4.compress_sublayer(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant4.min_error(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant4.plot_errors(SUBLAYER, plot_first_iter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about 2B Factors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_comp_2B_factors_incoh = ActivationAwareWeightCompressor(\n",
    "    model_params=ModelParameters(\n",
    "        base_model=BASE_MODEL\n",
    "    ),\n",
    "    data_params=DataParameters(),\n",
    "    hessian_save_path=HESSIAN_SAVE_PATH,\n",
    "    quant_params=ActivationAwareQuantParams(\n",
    "        Q_bits=2,\n",
    "        L_bits=2, R_bits=2,\n",
    "        lattice_quant_LR=True,\n",
    "        rank=RANK,\n",
    "        activation_aware_Q=True,\n",
    "        activation_aware_LR=True,\n",
    "        hadamard_transform=True,\n",
    "        incoherence_process_LR=True,\n",
    "        iters=QLR_ITERS,\n",
    "        lplr_iters=LPLR_ITERS,\n",
    "        rand_svd=True,\n",
    "        update_order=[\"Q\", \"LR\"]\n",
    "    ),\n",
    "    compute_hessians=False,\n",
    "    quant_device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant4 = weight_comp_2B_factors_incoh.get_layer_quantizer(LAYER)\n",
    "layer_quant4.compress_sublayer(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant4.min_error(SUBLAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_quant4.plot_errors(SUBLAYER, plot_first_iter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
